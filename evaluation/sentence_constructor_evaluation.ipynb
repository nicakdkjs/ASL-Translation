{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2f0973c",
   "metadata": {},
   "source": [
    "# Sentence Construction Model Evaluation\n",
    "\n",
    "This notebook compares different models for generating grammatically correct English sentences from ASL-style input word sequences. We evaluate:\n",
    "\n",
    "- A fine-tuned **T5 transformer model**\n",
    "- A **simple rule-based baseline**\n",
    "\n",
    "Evaluation is based on BLEU score accuracy against ground truth sentences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7001bdd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_words</th>\n",
       "      <th>target_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['i', 'want', 'apple']</td>\n",
       "      <td>I want an apple.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['mom', 'say', 'no']</td>\n",
       "      <td>Mom says no.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['dog', 'sleep', 'bed']</td>\n",
       "      <td>A dog sleeping on a bed.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['thankyou', 'mom']</td>\n",
       "      <td>Thank you, mom.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['go', 'outside', 'play']</td>\n",
       "      <td>Let's go outside to play.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 input_words            target_sentence\n",
       "0     ['i', 'want', 'apple']           I want an apple.\n",
       "1       ['mom', 'say', 'no']               Mom says no.\n",
       "2    ['dog', 'sleep', 'bed']   A dog sleeping on a bed.\n",
       "3        ['thankyou', 'mom']            Thank you, mom.\n",
       "4  ['go', 'outside', 'play']  Let's go outside to play."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load expanded \n",
    "df = pd.read_csv(\"Sentence_Construction_Dataset.csv\")  \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c13a63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load T5 model\n",
    "t5 = pipeline(\"text2text-generation\", model=\"mrm8488/t5-base-finetuned-common_gen\")\n",
    "\n",
    "def t5_generate(words):\n",
    "    prompt = \" \".join(words)\n",
    "    result = t5(prompt, max_new_tokens=30, num_beams=4, clean_up_tokenization_spaces=True)\n",
    "    sentence = result[0]['generated_text'].strip()\n",
    "\n",
    "    # Format sentence\n",
    "    sentence = sentence[0].upper() + sentence[1:]\n",
    "    if not sentence.endswith((\".\", \"!\", \"?\")):\n",
    "        sentence += \".\"\n",
    "    return sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de05e0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rule_based_generate(words):\n",
    "    if not words:\n",
    "        return \"\"\n",
    "    sentence = \" \".join(words).capitalize()\n",
    "    if not sentence.endswith(\".\"):\n",
    "        sentence += \".\"\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3382dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "gpt2 = pipeline(\"text-generation\", model=\"distilgpt2\")  # or \"gpt2\"\n",
    "\n",
    "def gpt2_generate(words):\n",
    "    prompt = \" \".join(words)\n",
    "    result = gpt2(prompt, max_length=30, num_return_sequences=1)\n",
    "    sentence = result[0]['generated_text'].strip()\n",
    "    \n",
    "    # Cut off trailing weird continuations (you can improve this)\n",
    "    sentence = sentence.split(\".\")[0] + \".\"\n",
    "    return sentence[0].upper() + sentence[1:] if sentence else \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6715cc61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "bart = pipeline(\"text2text-generation\", model=\"facebook/bart-large-cnn\")\n",
    "\n",
    "def bart_generate(words):\n",
    "    prompt = \" \".join(words)\n",
    "    result = bart(prompt, max_length=30, num_beams=4, clean_up_tokenization_spaces=True)\n",
    "    sentence = result[0]['generated_text'].strip()\n",
    "    return sentence[0].upper() + sentence[1:] + (\"\" if sentence.endswith(\".\") else \".\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29abb8f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "c:\\Users\\ngnic\\OneDrive\\Documents\\school\\year 3\\ASL-translation\\venv310\\lib\\site-packages\\transformers\\generation\\utils.py:1633: UserWarning: Unfeasible length constraints: `min_length` (56) is larger than the maximum possible length (30). Generation will stop at the defined maximum length. You should decrease the minimum length and/or increase the maximum length.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "\n",
    "smoothie = SmoothingFunction().method4\n",
    "\n",
    "t5_bleus = []\n",
    "rule_bleus = []\n",
    "gpt2_bleus = []\n",
    "bart_bleus = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    words = eval(row['input_words']) if isinstance(row['input_words'], str) else row['input_words']\n",
    "    target = row['target_sentence']\n",
    "\n",
    "    # Generate predictions\n",
    "    t5_sent = t5_generate(words)\n",
    "    rule_sent = rule_based_generate(words)\n",
    "    gpt2_sent = gpt2_generate(words)\n",
    "    bart_sent = bart_generate(words)\n",
    "\n",
    "    # BLEU scores\n",
    "    t5_bleus.append(sentence_bleu([target.split()], t5_sent.split(), smoothing_function=smoothie))\n",
    "    rule_bleus.append(sentence_bleu([target.split()], rule_sent.split(), smoothing_function=smoothie))\n",
    "    gpt2_bleus.append(sentence_bleu([target.split()], gpt2_sent.split(), smoothing_function=smoothie))\n",
    "    bart_bleus.append(sentence_bleu([target.split()], bart_sent.split(), smoothing_function=smoothie))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "73917f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average BLEU score (T5):        0.6471\n",
      "Average BLEU score (Rule-based): 0.0422\n",
      "Average BLEU score (GPT-2):       0.0221\n",
      "Average BLEU score (BART):        0.0207\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(f\"Average BLEU score (T5):        {np.mean(t5_bleus):.4f}\")\n",
    "print(f\"Average BLEU score (Rule-based): {np.mean(rule_bleus):.4f}\")\n",
    "print(f\"Average BLEU score (GPT-2):       {np.mean(gpt2_bleus):.4f}\")\n",
    "print(f\"Average BLEU score (BART):        {np.mean(bart_bleus):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15a856e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Words: ['grandma', 'bake', 'cake']\n",
      "Target: A grandma is baking a cake.\n",
      "T5 Output: A grandma is baking a cake.\n",
      "Rule Output: Grandma bake cake.\n",
      "--------------------------------------------------\n",
      "Input Words: ['cat', 'jump', 'table']\n",
      "Target: The cat jumped on the table.\n",
      "T5 Output: A cat is jumping on a table.\n",
      "Rule Output: Cat jump table.\n",
      "--------------------------------------------------\n",
      "Input Words: ['dog', 'bark', 'loud']\n",
      "Target: A dog is barking loudly.\n",
      "T5 Output: A dog is barking loudly.\n",
      "Rule Output: Dog bark loud.\n",
      "--------------------------------------------------\n",
      "Input Words: ['girl', 'clap', 'happy']\n",
      "Target: The girl is clapping because she is happy.\n",
      "T5 Output: A girl is clapping and happy.\n",
      "Rule Output: Girl clap happy.\n",
      "--------------------------------------------------\n",
      "Input Words: ['boy', 'run', 'grass']\n",
      "Target: A boy is running on the grass.\n",
      "T5 Output: A boy is running on the grass.\n",
      "Rule Output: Boy run grass.\n",
      "--------------------------------------------------\n",
      "Input Words: ['child', 'draw', 'sun']\n",
      "Target: A child draws the sun.\n",
      "T5 Output: A child draws the sun.\n",
      "Rule Output: Child draw sun.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    words = eval(df.iloc[i]['input_words']) if isinstance(df.iloc[i]['input_words'], str) else df.iloc[i]['input_words']\n",
    "    print(\"Input Words:\", words)\n",
    "    print(\"Target:\", df.iloc[i]['target_sentence'])\n",
    "    print(\"T5 Output:\", t5_generate(words))\n",
    "    print(\"Rule Output:\", rule_based_generate(words))\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2f2c84b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAGzCAYAAADT4Tb9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAA7zElEQVR4nO3dB5gUVdr28WeGkSAZychKMIAiYUkiIgYEs6yuixhARMwsyqsIvi6IuIKLCq6woijoa0TdNWcRFQVBgiIqGSXnIQ2Z6e+6j1/1dvf0zPSMAz1z5v+7rmLo09XV51RVVz11QlVKKBQKGQAAgCdSk50BAACAgkRwAwAAvEJwAwAAvEJwAwAAvEJwAwAAvEJwAwAAvEJwAwAAvEJwAwAAvEJwAwAAvEJwAwBFREpKit12223mq3r16tm1116b73Vz3333FXieUDQR3MBr//rXv9xBr23btsnOSqE8kWjdBFPp0qXtuOOOs7vuusu2bNkSNa9OGppn06ZN2S7v888/j1pe7PTKK68kdJJ+/fXX3ftaXm5++OEH+/Of/2zHHHOMy3+dOnXsnHPOsccffzxP6wLxt+MLL7wQd5727du795s0aXLY8wckIi2huYAi6sUXX3Qn8ZkzZ9qSJUvs2GOPTXaWCpXmzZvb//zP/7j/79mzx2bPnm2jR4+2L774wq2z/PjrX/9qrVu3zpLerl07K0jTpk2zM8880/7whz9Ynz59rGbNmrZy5Ur75ptv7LHHHrO+ffsW6PcVNwoWX3rpJbv66quj0n/55Re37vU+UFgR3MBby5cvdwfh//znP3bjjTe6QGfIkCGHNQ+ZmZm2b9++QnsiUE1H5Mnr+uuvt3LlytnDDz9sixcvdjU5edWhQwdXm3Ko/f3vf7eKFSvat99+a5UqVYp6b8OGDXY47dq1y4488kjzyfnnn29vv/22q62rWrVqOF0BT40aNdy+kZ6entQ8AtmhWQreUjBTuXJlu+CCC9zJVq8D+/fvtypVqlivXr2yfG779u0uGLnzzjvDaXv37nWBkWp+SpUqZXXr1rUBAwa49EhBc4u+66STTnLzfvjhh+49BQynnnqqHXXUUVamTBlr2bKla4KJtXv3blf7oRNK+fLl7eKLL7bVq1fH7VOg9Ouuu86dbPRd+s4JEyb8rvWmGhBJSyvc1z5Lly515Y0NbKR69epZ0tTE0qZNGxeEaL84/fTT7eOPP87SjBlst9q1a9utt95qW7dujZrnjDPOcM0xquXSMrS8e+65J0/7ySeffGKnnXaay7uCyRNOOCG8jERo/9JntJ9qP/ryyy/D702ZMsXtK2+88UaWzykw0XvTp0/P9TsuueQSV4bXXnstyzL+8pe/WIkSJbJ85sCBAzZs2DBr2LCh+6xqTVWu2PKHQiF74IEH7Oijj3brTzVwP/74Y9x8aP3ffvvtbl1qmVq3Dz30kLtwALJTuI9ewO+gE8Cll15qJUuWtO7du9sTTzzhrvLVZHLEEUfYn/70J1er8+STT7p5Am+++aY7GF9xxRXutQ6iCjC++uoru+GGG6xx48aur8eoUaNs0aJFbv5In332mb366qsuyFGAogO8qKlEy7nqqqtcbY76oFx++eX27rvvugAsoA6V+vw111xjp5xyimsiinw/sH79evd+EFBVq1bNPvjgA+vdu7cL0HRCyI2CvKAfjZql5s6da48++qg7adevXz9f633Hjh1x++YoqFNeC4r62egkPX/+/Fz7fgwdOtQFhgou77//fre9Z8yY4bZV586d3Tx6X/N16tTJbr75Zlu4cGF4n/n666/dPhPYvHmznXfeeW4fUc2XgstE9xOdxC+88EJr2rSpy4tO2Goy1XckQvvDpEmTXACszyogO/fcc10zotaDgi8FAtr/tY9HUpoCj0SaCBV0KMB5+eWX3fqQ77//3uX/6aeftnnz5mX5jGr+nnvuOXcxoeZOrePhw4fbzz//HBVsDR482AU3qh3SNGfOHLcd9LuIrRHr2LGjC+JV+6omSNXGDho0yNauXeuaUIG4QoCHZs2aFdLu/cknn7jXmZmZoaOPPjrUr1+/8DwfffSRm+edd96J+uz5558fatCgQfj1888/H0pNTQ1NnTo1ar5x48a5z3/99dfhNL3WvD/++GOWPO3atSvq9b59+0JNmjQJnXXWWeG02bNnu2XcfvvtUfNee+21Ln3IkCHhtN69e4dq1aoV2rRpU9S8V1xxRahixYpZvi/WMccc45YZO7Vv3z7LMvW9em/jxo3ZLm/KlClxlxdMa9eujVpPt956a9zlvPbaa+59LS8nH3/8cahEiRJuateuXWjAgAFum2q9Rlq8eLHbJn/6059CBw8ejHpP+4Vs2LAhVLJkyVDnzp2j5hkzZozLy4QJE8JpHTt2dGna/pES3U9GjRqV67rMTrAutX8Hfv3111Dp0qVd+QKDBg0KlSpVKrR169ZwmsqYlpYWtQ/ltB21Hd59991QSkpKaMWKFe69u+66K/zb0Ho46aSTwp/77rvv3Oeuv/76qOXdeeedLv2zzz6LWtcXXHBBeP3LPffc4+br2bNnOG3YsGGhsmXLhhYtWhS1zIEDB7rtHuQrWDe5lQ3FB81S8JKuUHU1repuUY1Bt27dXG3JwYMHXdpZZ53lalZ0FRxQHwI1GWjegKrldRXeqFEjVyMRTPp80AwQSVeaJ554YpY8qSkq8nu2bdvm+qfoqjUQNGHdcsstUZ+N7RyrY/m///1vu+iii9z/I/PVpUsXt+zI5WZHo8hUXk2qQVI/Fl2ZqwZCzWP5oavyYJmRk5oBC5JGRanmRnlVjcI//vEPV3b1I1JfkYBqTFSronylpkYf8oKapE8//dTVGqi2K3IedVSuUKGCvffee1GfU41JbJNmovtJ0Iz21ltv5atpRbUuaooKqDZDNSwfffRReN/u0aOHq32MbPbUfq5mo9gOwjlRbYq2m3432s/0V7Wg8bz//vvub//+/aPSgw7rwToM1rX26ciavHg1jVqn+o2oGTFynap2TWWNbI4DItEsBe/ooKeDsAIbdSqOPJE/8sgjNnnyZHfQVp+Syy67zPUh0IlAJyw1U6mpJjK4UcdaVaur2See2M6r2TXnKHhQVfx3330X1Qch8gD/66+/upNr7DJiR3lt3LjR9UV46qmn3JRIvuJRcKcTRUDNX+rLoWYFNT3kZ8TRySefHLXM/EqkCUtNjNpmOlkqwFHTh5qBlH+tZwWZ6pujdRov4Ixc76KyR1LzVYMGDcLvBxRARTZl5mU/0b6ldasmnIEDB9rZZ5/tmk+V59jgK554nbyPP/5414Sj/UJ9phRgad0oyFczpej/asbMy4hBNcWp6VS/EfVX0mi0K6+8Mu68wb4bu3zlRwFdsA6Dv7Hl0HpTEBO7TtX8lehvDwgQ3MA76keh9ngFOJH3VgnoIB/0s1CfCfW5UV+Vrl27ur4uOjE0a9YsPL+urnXCVl+UeNS/IbsamsDUqVNdDYP6sqiPRK1atdyJY+LEie7EkVfBFb+uwnv27Bl3HvXpyA+dbEVXxYdqOLUCyexqhnSSlryMMFOgoZO5Jp3oVauiq/5DNTou3jZOdD/RZ7VuVZOj2gzV1qlWRTU86uAcr6Nufqj2pl+/frZq1SoXTGuI/JgxY/K8HAUz48aNc32S9LvIKUiUguxXpXWqGjp1yo5H2xqIh+AG3lHwotEyY8eOzfKervJ1da+DtU4yCjYUaOjkotErCoz+93//N+oz6oCpWgGd9PN74FYTkk7WajrQiT2g4Ca2k6wO6KpxiryyVYfTSLqS1Ugq1VIVRC1JJDVdyM6dO+1QUTnVYTeeIF3z5EerVq3cXwW4wfbTOv3pp5/cfX2yy0/w3aqpCahGSNsikXWcl/1ENRyaT5OCoQcffNDtdwp4cvsu1WbEUodldQCOrOFQ4K4mInUIViCpYDqyRjJR+l2o6Us399MopewE+67yp+a5yI7vqmUM1nHwV/NFrmvVOsUOLdc61X5Y0Ps4/EefG3hFB3EFMBqNomr+2EmjijSaJ+iToZOM0t955x17/vnn3Yk99gSgYa8arTF+/Pi435eRkZFrvnQ1rhNe0CciuBla7Egr9RkR1e5Eir3jrpanJjUFTRotFEsnivzSupDI2quCphEyqknQcOpIOgkqOFUQEgxJz44Cgd/6kcbv+xE0MalGTttZI5Ni+7gEn9fJU7U///znP6OW+cwzz7j+S/FGq8VKdD+JvfuzBEFX7JDpeNTPKLI/lZqK1H9HtZGRtT5qctSILg2B1zrViKrI+9UkSvut1otqwTSCL6dtKrEjmIKarGAdal0r0NI+Hbmu44180jpVeXVREEv7ShCIA7GouYFXFLQoeFETUDzqc6CrWx3sgyBGf3Wg1cFbzQqRV52iA7qaq2666SZ3QtWt5xWkLFiwwKXrwBvUFmRHB3Yd5HWCUTW/+gqoZkn9EyKH1KqjqIIWHeg13DgYCq4rc4msERgxYoTLj/oSqeOrmgt04tSJT502451EY+lkHNxiP+i3omY6nQTjNUmpDLE3q1PgEHmPFjXBaVh5vGayoKlMfU3UbKSaMw3xVVPgmjVr7Nlnn3U1LrE1WvEof2rC0nBnfV751zBh1cJp+H3Q4VfrWLUiuv+KOqeqf4tqzzTEW/ey0VBl7RMaXqyh4NpG2n9Ui6MgU01diXTCTXQ/UZClZintE6rF0L6g79E9X1RLkhsN91YQHDkUXJT3eE1TwQ0VVf78UodlTTlRMKwmUvUBU+ChjvUanq6h4Qowg879Wte6h5TWuy5CFBTpFgRqGo4NvvQoEP2mNZ9ukaDfh4JEDbFXZ2ldIOQnYEMxkOzhWkBBuuiii9yw2IyMjGzn0bDqI444IjzcWcNR69at64aSPvDAA3E/o+HFDz30kBv6qiG2lStXDrVs2TI0dOjQ0LZt2xIa4vzMM8+EjjvuOPf5Ro0ahSZOnBgeYh1JedcyqlSpEipXrlyoa9euoYULF7r5RowYETXv+vXr3bzKv8pUs2bN0Nlnnx166qmncl1XsUPBNYy5evXqoe7du4eWLFkSNW+Qz3iThuQmMhQ8dpjuqlWr3LDhOnXquCHKKu+FF14Y+uabb0KJ+OCDD0LXXXedW5daTxpefOyxx4b69u3r1kssDedu0aJFePtpKHNwq4DIod9antZljRo1QjfffHMoPT09ap7YIdB53U8mT54cuuSSS0K1a9d2edZfrfPY4c7xBPvXCy+8EN6XVKbshs3v3bvX5UG3Bti9e3coEZFDwXMSbz3s37/flbV+/fpuHWq/1LD0PXv2RM2n4faaT7cyKFOmTOiMM84IzZ8/3+2TkUPBZceOHW4Z2rZaX1WrVg2deuqpoYcffjhq2D9DwREpRf8kO8ACkDON/GnRooWrZdFNAIFEqNlGtVO6ZYCa2IDigj43QCETbxSRmqnU/KNmHCBR6tOl/ldqngKKE/rcAIWMbkanjrbqo6B78agvgibd0j922DkQjx57oL5c6mejGj/1fwGKE5qlgEJGd/NV51ANXdYwWA3DVWdVdYot7A+zROGgzrdqwtQoLHXSzu3ZW4BvkhrcaMTAyJEj3VWqRkjo/iPqVZ8T3WtB927QLeJ1FXvvvfe6HzIAAEDS+9xoSJ+GD8a72Vo8upmWhk+qul4dLPUsEt3CPN49EAAAQPFUaJqldP+O3Gpu7r77bne78siblukunLqnQvDAQQAAULwVqQZ83aky9jbcuplVvKfJBnTHz8i7fuoOpbq52VFHHVWgz0ABAACHjupidJNW3d4gt4fMFqngZt26dVajRo2oNL3evn27Gz4b72F2ugtmvDt3AgCAokePHNEdvb0JbvJDt1RXB+SAnhOj0Sfqv1OhQgWXpghQk2p1Ip89E6TrFuqRrXfZpQfPD4p93knwvJfI5wrllK4RMVpuZLqWq/lj85hdOmWiTJSJMlEmyuRTmfRgVT1aRQ8Nzk2RCm70ID09YTaSXitIiVdrI3r2SuRTmANVqlQJBzcAAKBoSKRLSZG6Q3G7du1s8uTJWe4JonQAAICkBze6QZmGdGsSNRXp/ytWrAg3KUXeNlxP2122bJkNGDDAPWlXT8PV03bvuOOOpJUBAAAULkkNbmbNmuVuDa5J1DdG/x88eLB7rRv7BYGO1K9f3w0FV22N7o/zyCOP2NNPP+1GTAEAABSq+9wcLhpZVbFiRdexmD43AAD4d/4uUn1uAAAAckNwAwAAvEJwAwAAvEJwAwAAvEJwAwAAvEJwAwAAvEJwAwAAvEJwAwAAvEJwAwAAvEJwAwAAvEJwAwAAvEJwAwAAvEJwAwAAvEJwAwAAvEJwAwAAvEJwAwAAvEJwAwAAvEJwAwAAvEJwAwAAvEJwAwAAvEJwAwAAvEJwAwAAvEJwAwAAvEJwAwAAvEJwAwAAvEJwAwAAvEJwAwAAvEJwAwAAvEJwAwAAvEJwAwAAvEJwAwAAvEJwAwAAvEJwAwAAvEJwAwAAvEJwAwAAvEJwAwAAvEJwAwAAvEJwAwAAvEJwAwAAvEJwAwAAvEJwAwAAvEJwAwAAvEJwAwAAvEJwAwAAvEJwAwAAvEJwAwAAvEJwAwAAvEJwAwAAvEJwAwAAvEJwAwAAvEJwAwAAvEJwAwAAvEJwAwAAvEJwAwAAvEJwAwAAvEJwAwAAvEJwAwAAvEJwAwAAvEJwAwAAvEJwAwAAvEJwAwAAvEJwAwAAvEJwAwAAvJL04Gbs2LFWr149K126tLVt29ZmzpyZ4/yjR4+2E044wcqUKWN169a1O+64w/bs2XPY8gsAAAq3pAY3kyZNsv79+9uQIUNszpw51qxZM+vSpYtt2LAh7vwvvfSSDRw40M3/888/2zPPPOOWcc899xz2vAMAgMIpqcHNo48+an369LFevXrZiSeeaOPGjbMjjzzSJkyYEHf+adOmWfv27e3KK690tT2dO3e27t2751rbAwAAio+0ZH3xvn37bPbs2TZo0KBwWmpqqnXq1MmmT58e9zOnnnqqvfDCCy6YadOmjS1btszef/99u+aaa7L9nr1797opsH37dvf3wIEDbgq+V1NmZqabIvOj6eDBgxYKhXJNL1GihKWkpISXG5kumj+R9LS0NLfcyHQtV/PH5jG7dMpEmSgTZaJMlMm3MhX64GbTpk0uozVq1IhK1+sFCxbE/YxqbPS50047zRVcG+mmm27KsVlq+PDhNnTo0Czpc+fOtbJly7r/V6tWzRo2bGjLly+3jRs3huc5+uij3bRo0SLbtm1bOL1BgwZWvXp1mz9/vu3evTuc3qhRI6tUqZJbduRGaNq0qZUsWdJmzZoVlYdWrVq5IG/evHnhNO0IrVu3dt8XuR7Ux0jNdiq/grpAxYoVrXHjxrZmzRpbtWpVOJ0yUSbKRJkoE2XyqUw//fSTJSolFBkeHUYqbJ06dVxTU7t27cLpAwYMsC+++MJmzJiR5TOff/65XXHFFfbAAw+4zsdLliyxfv36uaatv/3tbwnX3Kgj8ubNm61ChQoujciYMlEmykSZKBNlKtxlSk9PtypVqrjAJzh/F7rgRhGh+te8/vrr1rVr13B6z549bevWrfbWW29l+UyHDh3slFNOsZEjR4bT1Ex1ww032M6dO13hc6PgRtFkIisHAAAUDnk5fyetQ7GqwVq2bGmTJ08OpymC0+vImpxIu3btyhLABNFlkmI0AABQyCStz41oGLhqatS2pw7CuodNRkaGGz0lPXr0cE1X6jcjF110kRth1aJFi3CzlJqjlB4EOQAAoHhLanDTrVs315lo8ODBtm7dOmvevLl9+OGH4U7GK1asiKqpuffee10bnv6uXr3adUpSYPP3v/89iaUAAACFSdL63CQLfW4AACh6ikSfGwAAgEOB4AYAAHiF4AYAAHiF4AYAAHiF4AYAAHiF4AYAAHiF4AYAAHiF4AYAAHiF4AYAAHiF4AYAAHiF4AYAAHiF4AYAAHiF4AYAAHiF4AYAAHiF4AYAAHiF4AYAAHiF4AYAAHiF4AYAAHiF4AYAAHiF4AYAAHiF4AYAAHiF4AYAAHiF4AYAAHiF4AYAAHiF4AYAAHiF4AYAAHiF4AYAAHiF4AYAAHiF4AYAAHiF4AYAAHiF4AYAAHiF4AYAAHiF4AYAAHiF4AYAAHiF4AYAAHiF4AYAAHiF4AYAAHiF4AYAAHiF4AYAAHiF4AYAAHiF4AYAAHiF4AYAAHiF4AYAAHiF4AYAAHiF4AYAAHiF4AYAAHiF4AYAAHiF4AYAAHiF4AYAAHglLdkZ8M2IuZuSnYVia2CLqsnOAgCgEKDmBgAAeIXgBgAAeIXgBgAAeIXgBgAAeIXgBgAAeIXgBgAAeIXgBgAAeIXgBgAAeIXgBgAAeIXgBgAAeIXgBgAAeIXgBgAAeIXgBgAAeCXpwc3YsWOtXr16Vrp0aWvbtq3NnDkzx/m3bt1qt956q9WqVctKlSplxx9/vL3//vuHLb8AAKBwS0vml0+aNMn69+9v48aNc4HN6NGjrUuXLrZw4UKrXr16lvn37dtn55xzjnvv9ddftzp16tivv/5qlSpVSkr+AQBA4ZPU4ObRRx+1Pn36WK9evdxrBTnvvfeeTZgwwQYOHJhlfqVv2bLFpk2bZkcccYRLU60PAADA7wpupk6dak8++aQtXbo0XIPy/PPPW/369e20005LaBmqhZk9e7YNGjQonJaammqdOnWy6dOnx/3M22+/be3atXPNUm+99ZZVq1bNrrzySrv77rutRIkScT+zd+9eNwW2b9/u/h44cMBNwfdqyszMdFNkfjQdPHjQQqFQrulBHlIyD0blIZTyW+tfSigzsfTUEmahUHR6Sspv82ebnmkpEXkJpaSY5ZDulhGVnuqWlW16EShTXrZTSkpKePtHpovmTyQ9LS3NLTcyXcvV/LH7UnbpBbnvUSbKRJkok+9lOmTBzb///W+75ppr7KqrrrK5c+eGA4dt27bZgw8+mHD/l02bNrmM1qhRIypdrxcsWBD3M8uWLbPPPvvMfbe+Z8mSJXbLLbfY/v37bciQIXE/M3z4cBs6dGiWdOW9bNmy7v8Kkho2bGjLly+3jRs3huc5+uij3bRo0SJXvkCDBg1c09j8+fNt9+7d4fRGjRq5v7W3LLaUiA22rkpDO5iaZnU2LYzKw+qqJ1iJzANWc8vScFooNdVWV21kpfdnWNWtK8LpB9JKueWU3bPVKu9YG07fU7Ksbap0jFXYtdkqZPw37xllKll6+dpWeec6K7t7azh9e9lqbjpq20orvS8jnJ5evpZllKlsNdKXW9qB/waDmyr9wfaULFckypSX7aSmTO0DkT+Wpk2bWsmSJW3WrFlRZWrVqpULxufNmxdO0w+2devW7vsi99cyZcpYs2bN3P6t/TVQsWJFa9y4sa1Zs8ZWrVoVTi/IfY8yUSbKRJl8LtNPP/1kiUoJRYZHCWjRooXdcccd1qNHDytfvrx9//337ou1ws477zxbt25dQstRYVXjoyYm1cYEBgwYYF988YXNmDEjy2fUeXjPnj1uhQRRpZq2Ro4caWvX/vfkmFvNTd26dW3z5s1WoUKFAo+MH/puc5Go5fCx5uauppWL1RUMZaJMlIkyFacypaenW5UqVVzgE5y/C6zmRp19Tz/99CzpitA0kilRVatWdYVev359VLpe16xZM+5nNEJKfW0im6AUFSqgUoSp6DOWRlRpiqUNpClSsAJjZdfklV26O5HHS0/JQ7o7weclPdVCKZZw+m9BSx7Si0CZ8rqdYrd/ftL1442Xnt2+lNd0ykSZskunTJQpp7yXKEZlKpCh4Ao81BwU66uvvnI1OIlSINKyZUubPHlyOE0RnF5H1uREat++vfvuyEhP1VcKeuIFNgAAoPjJc3Cj0U39+vVzzUaK3tS89OKLL9qdd95pN998c56WpWHg48ePt+eee85+/vln9/mMjIzw6Ck1fUV2ONb7Gi2l71dQo5FV6uejDsYAAAD5apbSEG3VnJx99tm2a9cu10SlZh8FN3379s3Tsrp16+Y6Ew0ePNg1LTVv3tw+/PDDcCfjFStWRFVZqa/MRx995Pr8qBOU+uwo0NFoKQAAgDx3KFYnn6+//toFFkceeaRrItq5c6edeOKJVq5cuSKxRtWhWP2DEumQlB8j5m4q8GUiMQNbVE12FgAAheD8naeaG3Xm6dy5s2tC0pAyBTUAAABFus9NkyZNosaxAwAAFOng5oEHHnD9a9599113bxlVE0VOAAAARapD8fnnn+/+XnzxxW60VEBdd/Q6L7dHBgAASHpwM2XKlALPBAAAQNKCm44dOxbYlwMAABSKp4LrMQvPPPOMGzUlJ510kl133XVuiBYAAECR6lCsJ4fqaZ6jRo1ydwvWpIdXKm3OnDmHJpcAAACHquZGdwdWZ2I9NiF4cJaeMnr99dfb7bffbl9++WVeFwkAAJC84EY1N5GBjVtIWpoNGDDAWrVqVXA5AwAAOBzNUrrlsZ75FGvlypVWvnz5/OQBAAAgecGNHnbZu3dvmzRpkgtoNL3yyiuuWap79+4FlzMAAIDD0Sz18MMPu5v19ejRw/W1kSOOOMJuvvlmGzFiRH7yAAAAkLzgpmTJkvbYY4/Z8OHDbenSpS5NI6X0lHAAAIAiF9zoUeN6xEKVKlXs5JNPDqdrSLg6Fuf2GHIAAIBC1efmiiuucH1sYr366qvuPQAAgCIV3MyYMcPOPPPMLOlnnHGGew8AAKBIBTd79+4NdySOtH//ftu9e3dB5QsAAODwBDdt2rSxp556Kkv6uHHjrGXLlvnLBQAAQLI6FD/wwAPWqVMn+/777+3ss892aZMnT7Zvv/3WPv7444LKFwAAwOGpuWnfvr1Nnz7d6tat6zoRv/POO3bsscfavHnzrEOHDvnLBQAAQLJqbqR58+b24osvFlQeAAAADn9wo07Eur9NqVKlwmnr1693fW0yMjLck8JPO+20gssZAADAoQxu+vTp4+5O/OSTT7rXO3bssNatW9uePXusVq1aNmrUKHvrrbfs/PPPz08+AAAADm+fm6+//touu+yy8Ov/+7//czU5ixcvdp2L+/fvbyNHjiyYXAEAABzq4Gb16tV23HHHhV9rhJSCnYoVK7rXPXv2tB9//DG/+QAAADi8wU3p0qWjbtL3zTffWNu2baPe37lzZ8HkCgAA4FAHNxoh9fzzz7v/T5061XUmPuuss8Lv6wnhtWvXzm8+AAAADm+H4sGDB9t5553n7m2zdu1au/baa11H4sAbb7zh7oEDAABQJIKbjh072uzZs91diGvWrGmXX355lpodPZoBAACgyNzEr3Hjxm6K54YbbiioPAEAABy+xy8AAAAUZgQ3AADAKwQ3AADAKwQ3AACgeHYo3r59e9z0smXLWokSJQoyTwAAAIe+5qZSpUpWuXLlLFOZMmXshBNOsPHjx+c/FwAAAIe75mbKlClx07du3eruf3PXXXdZWlqa9erVq6DyBgAAcGhv4pedSy65xOrVq2ePP/44wQ0AAPCjQ7GCnyVLlhTU4gAAAJIb3Gzbts0qVqxYUIsDAABIXnCzf/9+GzlypLVt27YgFgcAAHDo+9xceuml2dbY/Pjjj5aSkmJTp07Nf04AAAAOZ3CTXZNT3bp17bLLLrOrrrqKZikAAJB0CQc3EydOPLQ5AQAAOJx9bjZs2JDj+wcOHLCZM2cWRJ4AAAAOfXBTq1atqADn5JNPtpUrV4Zfb9682dq1a5f/nAAAABzO4CYUCkW9/uWXX9woqZzmAQAAKNJPBdeIKQAAAG+CGwAAgCIzWkq1Mjt27LDSpUu75ie93rlzp23fvt29H/wFAAAoEsGNAprjjz8+6nWLFi2iXtMsBQAAikxwM2XKlEObEwAAgMMZ3Oip3znZtWuXfffddwWRJwAAgOR3KF68eLF16NChoBYHAACQL4yWAgAAXiG4AQAAXiG4AQAAxbND8dtvv53j+8uXLy+I/AAAABye4KZr1665zsN9bgAAQJEJbjIzMw9tTgAAAAoAfW4AAEDxrLkJbN682Y466ij3/5UrV9r48eNt9+7ddtFFF9npp59+KPIIAABQ8DU3P/zwg9WrV8+qV69ujRo1cncjbt26tY0aNcqeeuopO+uss+zNN9+0/Bg7dqxbth7K2bZtW5s5c2ZCn3vllVdcP59E+gMBAIDiIeHgZsCAAXbyySfbl19+aWeccYZdeOGFdsEFF9i2bdssPT3dbrzxRhsxYkSeMzBp0iTr37+/DRkyxObMmWPNmjWzLl262IYNG3L83C+//GJ33nknd0UGAABRUkJ6nHcCqlatap999pk1bdrUdu7caRUqVLBvv/3WWrZs6d5fsGCBnXLKKbZ161bLC9XUqAZozJgx4Y7LdevWtb59+9rAgQPjfubgwYOuCey6666zqVOnuu/MrtZo7969bgps377dLV/NayqDpKamuknfHdlxOkjX90WupuzSS5QoYQ99t9lSMg9G5SGU8lsMmRLKTCw9tYQesx6dnpLy2/zZpmdqY0YsO8Ush3S3jKj0VLesbNOLQJnualo54e2kGr8DBw5E5VHpovkTSU9LS3PLjUzXcjV/7L6UXXpB7nuUiTJRJsrkc5nS09OtSpUqrlIlOH//7j43W7ZssZo1a7r/lytXzsqWLWuVK1cOv6//79ixw/Ji3759Nnv2bBs0aFBUITp16mTTp0/P9nP333+/ax7r3bu3C25yMnz4cBs6dGiW9Llz57oySLVq1axhw4buXj0bN24Mz3P00Ue7adGiRW5lBho0aOC+f/78+a6/UUDNdVJ7y2JLidhg66o0tIOpaVZn08KoPKyueoKVyDxgNbcsDaeFUlNtddVGVnp/hlXduiKcfiCtlFtO2T1brfKOteH0PSXL2qZKx1iFXZutQsZ/855RppKll69tlXeus7K7/xtwbi9bzU1HbVtppfdlhNPTy9eyjDKVrUb6cks78N9gcFOlP9iekuWKRJnysp0qVark9oHIH6gC95IlS9qsWbOiytSqVSu3r86bNy+cph+sgnJ9nwL7QJkyZVzt46ZNm2zZsmXh9IoVK1rjxo1tzZo1tmrVqnB6Qe57lIkyUSbK5HOZfvrpJyvwmhsFHevXr3eZkvLly7tC169f373We7Vr184S5eVEBa5Tp45NmzbN2rVrF9UE9sUXX9iMGTOyfOarr76yK664wvX5UW3StddeS80NNTfU3FAmykSZKJPnZUo/FDU3okCiVKlS7v979uyxm266KVz7ERlAHCqqGbrmmmvcCC0FNolQfoM8x24gTZGCFRgr2MiJprsTebz0lDykuxN8XtJTLRTvHorZpP8WtOQhvQiUKa/bKXb75yddP9546dntS3lNp0yUKbt0ykSZcsp7iWJUprj5TnTGnj17Rr2++uqrs8zTo0cPywsFKMqsan0i6XXQBBZp6dKlriOxhp0HgqhPK3rhwoWuqgsAABRfCQc3EydOLPAvVzufOiRPnjw5PJxbwYpe33bbbVnmV5uhhqRHuvfee12NzmOPPeaamwAAQPGW55v4FTQNA1etkDovtWnTxkaPHm0ZGRnWq1evcG2Q+uWoY7Dug9OkSZOoz6uDlMSmAwCA4inpwU23bt1cb+nBgwfbunXrrHnz5vbhhx9ajRo13PsrVqyI2yYHAADwu0ZL+UKjpTQ8LZHe1vkxYu6mAl8mEjOwRWKdzAEAfp+/qRIBAABeIbgBAABeIbgBAABeIbgBAABeIbgBAABeIbgBAABeIbgBAABeIbgBAABeIbgBAABeIbgBAABeIbgBAABeIbgBAABeIbgBAABeIbgBAABeIbgBAABeIbgBAABeIbgBAABeIbgBAABeIbgBAABeIbgBAABeIbgBAABeIbgBAABeIbgBAABeIbgBAABeIbgBAABeIbgBAABeIbgBAABeIbgBAABeIbgBAABeIbgBAABeIbgBAABeIbgBAABeIbgBAABeIbgBAABeIbgBAABeIbgBAABeIbgBAABeIbgBAABeIbgBAABeIbgBAABeIbgBAABeIbgBAABeIbgBAABeIbgBAABeIbgBAABeIbgBAABeIbgBAABeIbgBAABeIbgBAABeIbgBAABeIbgBAABeIbgBAABeIbgBAABeIbgBAABeIbgBAABeIbgBAABeIbgBAABeIbgBAABeIbgBAABeIbgBAABeIbgBAABeIbgBAABeIbgBAABeKRTBzdixY61evXpWunRpa9u2rc2cOTPbecePH28dOnSwypUru6lTp045zg8AAIqXpAc3kyZNsv79+9uQIUNszpw51qxZM+vSpYtt2LAh7vyff/65de/e3aZMmWLTp0+3unXrWufOnW316tWHPe8AAKDwSQmFQqFkZkA1Na1bt7YxY8a415mZmS5g6du3rw0cODDXzx88eNDV4OjzPXr0yPL+3r173RTYvn27W/7mzZutQoUKLi01NdVN+m5NgSBd3xG5mrJLL1GihD303WZLyTwYlYdQym8xZEooM7H01BJmoVB0ekrKb/Nnm56pjRmx7BSzHNLdMqLSU92ysk0vAmW6q2nlhLdTSkqKHThwICqPShfNn0h6WlqaW25kupar+WP3pezSC3Lfo0yUiTJRJp/LlJ6eblWqVLFt27aFz9/ZSbMk2rdvn82ePdsGDRoUTlMB1NSkWplE7Nq1y/bv3+8KHM/w4cNt6NChWdLnzp1rZcuWdf+vVq2aNWzY0JYvX24bN24Mz3P00Ue7adGiRW5lBho0aGDVq1e3+fPn2+7du8PpjRo1cn9rb1lsKREbbF2VhnYwNc3qbFoYlYfVVU+wEpkHrOaWpeG0UGqqra7ayErvz7CqW1eE0w+klXLLKbtnq1XesTacvqdkWdtU6RirsGuzVcj4b94zylSy9PK1rfLOdVZ299Zw+vay1dx01LaVVnpfRjg9vXwtyyhT2WqkL7e0A/8NBjdV+oPtKVmuSJQpL9upUqVKbh+I/IE2bdrUSpYsabNmzYoqU6tWrdy+Om/evHCafrAKyvV9CxYsCKeXKVPG1T5u2rTJli1bFk6vWLGiNW7c2NasWWOrVq0KpxfkvkeZKBNlokw+l+mnn36yIlFzowLXqVPHpk2bZu3atQunDxgwwL744gubMWNGrsu45ZZb7KOPPrIff/zR9dmJRc0NNTc+XsFQJspEmShTcStTelGpufm9RowYYa+88orrhxMvsJFSpUq5KZY2kKZIwQqMFWzkRNPdiTxeekoe0t0JPi/pqRZKsYTTfwta8pBeBMqU1+0Uu/3zk64fb7z07PalvKZTJsqUXTplokw55b1EMSpT3HxbElWtWtVldv369VHpel2zZs0cP/vwww+74ObTTz911WoAAABJHy2ldr6WLVva5MmTw2mqotLryGaqWP/4xz9s2LBh9uGHH7p2QQAAgELTLKVh4D179nRBSps2bWz06NGWkZFhvXr1cu9rBJT65ahjsDz00EM2ePBge+mll9y9cdatW+fSy5Ur5yYAAFC8JT246datm+strYBFgUrz5s1djUyNGjXc+ytWrIhqk3viiSdcD+4///nPUcvRfXLuu+++w55/AABQuCT9PjeHm0ZLaXhaIr2t82PE3E0FvkwkZmCLqsnOAgCgEJy/k36HYgAAgIJEcAMAALxCcAMAALxCcAMAALxCcAMAALxCcAMAALxCcAMAALxCcAMAALxCcAMAALxCcAMAALxCcAMAALxCcAMAALxCcAMAALxCcAMAALxCcAMAALxCcAMAALxCcAMAALxCcAMAALxCcAMAALxCcAMAALxCcAMAALxCcAMAALxCcAMAALxCcAMAALxCcAMAALxCcAMAALxCcAMAALxCcAMAALxCcAMAALxCcAMAALxCcAMAALxCcAMAALxCcAMAALxCcAMAALxCcAMAALxCcAMAALxCcAMAALxCcAMAALxCcAMAALxCcAMAALxCcAMAALxCcAMAALxCcAMAALxCcAMAALxCcAMAALxCcAMAALxCcAMAALxCcAMAALxCcAMAALxCcAMAALxCcAMAALySluwMAEXBiLmbkp2FYmtgi6rJzgKAIoaaGwAA4BWCGwAA4BWCGwAA4BWCGwAA4BWCGwAA4BWCGwAA4BWGggMo1hjmnzwM88ehQnADAPASgWvxDVxplgIAAF4huAEAAF4pFMHN2LFjrV69ela6dGlr27atzZw5M8f5X3vtNWvUqJGb/+STT7b333//sOUVAAAUbkkPbiZNmmT9+/e3IUOG2Jw5c6xZs2bWpUsX27BhQ9z5p02bZt27d7fevXvb3LlzrWvXrm6aP3/+Yc87AAAofJIe3Dz66KPWp08f69Wrl5144ok2btw4O/LII23ChAlx53/sscfs3HPPtbvuussaN25sw4YNsz/+8Y82ZsyYw553AABQ+CR1tNS+ffts9uzZNmjQoHBaamqqderUyaZPnx73M0pXTU8k1fS8+eabceffu3evmwLbtm1zf7ds2WIHDhwIf6emzMxMN0XmRdPBgwctFArlml6iRAnbs3OHpWQejMpDKOW3GDIllJlYemoJs1AoOj0l5bf5s03PtJSIvIRSUsxySHfLiEpPdcvKNr0IlCk9vUTC2yklJSW8/SPTRfPHpu/ZsZ3tlKQybdmSmvB2ipeelpbmtn9kura/5tfvfe/2rYe9TD5up/yUKXLb5radIo/N2aXHHsuDbct2ssNeJm3bRLdToufc9PT03/IQ8V6hDG42bdrkClGjRo2odL1esGBB3M+sW7cu7vxKj2f48OE2dOjQLOn169f/XXlH4ZN1K8MHbFd/3ZfsDKBIbtsdO3ZYxYoVi/d9blQrFFnToyhRtTZHHXWUiyrxm+3bt1vdunVt5cqVVqFChWRnBwWIbesvtq2f2K7xqcZGgU3t2rUtN0kNbqpWreqqrNavXx+Vrtc1a9aM+xml52X+UqVKuSlSpUqVfnfefaUfEj8mP7Ft/cW29RPbNavcamwKRYfikiVLWsuWLW3y5MlRNSt63a5du7ifUXrk/PLJJ59kOz8AAChekt4spSajnj17WqtWraxNmzY2evRoy8jIcKOnpEePHlanTh3Xd0b69etnHTt2tEceecQuuOACe+WVV2zWrFn21FNPJbkkAACgMEh6cNOtWzfbuHGjDR482HUKbt68uX344YfhTsMrVqxwvaQDp556qr300kt277332j333GPHHXecGynVpEmTJJai6FPTne41FNuEh6KPbesvtq2f2K6/X0ookTFVAAAARUTSb+IHAABQkAhuAACAVwhuAACAVwhuAACAVwhugEJId8/O7nlpiTrjjDPs9ttvt8Lm2muvta5duyY7GwA8RnBTzE6YOU333ffb00Divaf7CSHxk3ew3o444gj3HLMBAwbYnj17kp01FCK69YXu23Xsscda6dKl3e0v2rdvb0888YTt2rXLzVOvXr3wvlS2bFn74x//aK+99lqW9+JN2g9j/ec//7FzzjnHqlWr5u58q5uffvTRR4e97MXtOKBJj/w599xzbd68eVnmvfHGG93d+oNtG0nH5WAZmkePZbjhhhvcY4Q+//zzXI/rn3/+uRVHSb/PDQ6ftWvXhv8/adIkd2+hhQsXhtPKlSsX/v/EiRPdDzHAIyvyRutO63D//v3uyfe6UaUONA899FCys4ZCYNmyZS6Q0e/qwQcftJNPPtnd0+SHH35wNyTVjUsvvvhiN+/9999vffr0cc8b0s1LdW8wvf/tt9+Gn6A9bdo0u+yyy9zvObhdf5kyZbJ875dffumCG32nvlv76EUXXWQzZsywFi1aHOa1UHyOA0Ewq/uzXXjhhe7+bQEFsrp41AXQhAkT7PLLL8+ynJNOOsk+/fRTt71//vlnu+6662zbtm32/PPPRx3XFSxrP5n4/79TqlSpYsURNTfFiJ6/FUx6PodOtpFpkcGNDnyR7+nKEonTiUrrTVdZaoLp1KmTe0xIcMWtO3FH0s0rg5qzePQAvb/85S9uu+hgdckll9gvv/ySaz4OHDhgt912m9veepbb3/72N/fwuYAOjro7ePny5V1+r7zyStuwYUP4/fT0dLvqqqvclb5OlrppZuSBM7d86WCsu5DrfV256gDOrbXMbrnlFktLS3N3V9f6a9y4sTVo0MCtv/fee88FHIFg2xx//PE2duxYtx3eeecdt02C32dwAqtevXrUbzyW9jttg9atW7ttqSBHf7U8HLrjgCb9xgcOHOh+M7pxbUC1NSeeeKJ7T8Gn3o+lfUXLUFCrY4kCIB1P9AijyOO09o3I76xZs6abpzgiuEFct956qzsZ6pEYuprghJR/8+fPd1fW+T3IqPanS5cu7iQ3depU+/rrr10gqqvCffv25fjZ5557zh0YZ86caY899pg9+uij9vTTT0cte9iwYfb999+7Pj4KTCKbMxQM/fTTT/bBBx+4K0Y1mWi/SDRfqml49tln3T701Vdfuar0N954w4qzzZs328cff+x+Y2pqikcXHvFoW6qpM7ftnig9y09PWS6uV/eH086dO+2FF15wzZAK9APPPPOMXX311S4YPe+889zvJSf6jaopsbgGLYmiWQpZqBr8rLPOsiOPPNIdhHWVqR/mX//612Rnrch499133YleNSd79+51jxAZM2ZMvpalJkSdhBSUBCc91Z6oNkTt6Z07d872s6o5GjVqlPvcCSec4Jo99FrNHKLq7YBqDv75z3+6q3ptb+Vf1edqrlDtTlDrlJd8qaZg0KBBdumll7r3x40bV+z7eCxZssRdLGh7RFLQGPTLUuAT24SpgEbBopoj9PssCA8//LDb1qo9wqE7DoiemVirVi2XFjxSaPHixfbNN9+4vlCiIEc1nWq+igxw9bvVclQTGuwjulBB9qi5QRa6Wld/AJ3U7r77bleNPXLkyGRnq0g588wz7bvvvnN9GdTfRg+CVZ+I/FCtik6IqiHRAU6TrrR1kFu6dKmrNQnSNb344ovhz55yyilRB0l1INUBNeirof5AagL5wx/+4Javh9JK0Cfg5ptvdv0BVKWu/UA1UInmSydh9Qdo27ZtVM1DECghmmrXtM+of4UC4oB+g1q3uthQwDNixAj30ODcRO4TN910U5b39Yy+oUOH2quvvuqas3DojgOatH1V06namV9//dW9rxpNpQW1oeeff7773Xz22WdRy1EgrGWon5X2B32mb9++SSlTUUHNDXKlk5OaLnTA5UFuiVFzg6qfgwNYs2bNXPVz79693VVbbDOfmniyoyvrli1bRgUtAfW7UPW0DnyB4KGzudGVpA6SmrRsLUtBjV4HzR7Bgfj99993bfxnn322q1UIrvhzyhfi036hgDOyM39QcxavI/Bdd93lmgoVpGjbZtdkFStynwg6GQcUsF5//fWuv4f6cODQHwdEtZxqfho/frwLLNVsrI7GCvoDuvDQMUO/tYB+48FyguBWn9dxGfER3CChg2TlypUJbPJJwYyeYK/qZnXY1Yk/coSDRjcsX748289r+K+agHR1HXuSCkQeQCOp5iiSqsDVgVRDShcsWOD6f+hgqeYrUQfXWMqvap80dejQwZ1sFdwkki9VwysPp59+unutZjrVFumzxZX6W2jEkpopdfWdXb+bgK7qs9u+OcnuMy+//LJrjlSAk0gNEAqOAlMdD3bv3u0uGNTfae7cue73GNlHTzW9W7duzXaUqpqt1DSpmtXatWsfxhIUHTRLIYpGTejqQj8wNTmoA6lGVFAF+vtodIMOYBrtooOSRimpOUlt6QoaIg9usTRaSSc4jaTRZxQIqU+L+kCtWrUqx+9VTYyCKtUS6KT2+OOPu+GioqYoXREqTUOT33777SxXgrpdwFtvveX2hR9//NH1F9DInkTzpe9S8KTOygqm1H9LB+3i7l//+pcL9NREpwBRnbW1jdThVOspp/3h91BTVI8ePVzfHdXIqtZAk5pCUPBU2x2sY21jHUdV46mmYNXkKrhUrW6TJk3CUzD6MF6NaGTzctOmTd2xGdkIoViaOHFiqGLFilnSP/jgg1Dz5s1D5cqVC5UtWzbUrFmz0Lhx40IHDx5MSj6Lop49e4YuueSSLOnDhw8PVatWLbR169ZQt27dQhUqVAjVrVs39Oyzz7r1PGTIkPC8+mm+8cYb4ddr164N9ejRI1S1atVQqVKlQg0aNAj16dMntG3btmzz0bFjx9Att9wSuummm9x3Va5cOXTPPfeEMjMzw/O89NJLoXr16rlltmvXLvT222+77547d657f9iwYaHGjRuHypQpE6pSpYor17JlyxLO1/79+0P9+vVz31+pUqVQ//793fzx1k9xs2bNmtBtt90Wql+/fuiII45wv7k2bdqERo4cGcrIyHDzHHPMMaFRo0bluqwpU6a47Zaenp7jfNonNF/spH0WBUvrNHIdly9fPtS6devQ66+/Hlq3bl0oLS0t9Oqrr8b97M033xxq0aKF+7+OCzo+xHr55Zfdb27FihVR38lv6zcp+ie7wAcAAKCooVkKAAB4heAGAAB4heAGAAB4heAGAAB4heAGAAB4heAGAAB4heAGAAB4heAGAAB4heAGAAB4heAGAAB4heAGAACYT/4fHZvDvOWPAAQAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model_names = ['T5', 'Rule-based', 'GPT-2', 'BART']\n",
    "bleu_means = [np.mean(t5_bleus), np.mean(rule_bleus), np.mean(gpt2_bleus), np.mean(bart_bleus)]\n",
    "\n",
    "plt.bar(model_names, bleu_means, color='skyblue')\n",
    "plt.title(\"Average BLEU Scores by Model\")\n",
    "plt.ylabel(\"BLEU Score\")\n",
    "plt.ylim(0, 1)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd141ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "c:\\Users\\ngnic\\OneDrive\\Documents\\school\\year 3\\ASL-translation\\venv310\\lib\\site-packages\\transformers\\generation\\utils.py:1633: UserWarning: Unfeasible length constraints: `min_length` (56) is larger than the maximum possible length (30). Generation will stop at the defined maximum length. You should decrease the minimum length and/or increase the maximum length.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "c:\\Users\\ngnic\\OneDrive\\Documents\\school\\year 3\\ASL-translation\\venv310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.809524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rule-based</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.717949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GPT-2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.260870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BART</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Model  Precision  Recall  F1 Score\n",
       "0          T5        1.0    0.68  0.809524\n",
       "1  Rule-based        1.0    0.56  0.717949\n",
       "2       GPT-2        1.0    0.15  0.260870\n",
       "3        BART        0.0    0.00  0.000000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Load model\n",
    "embedder = SentenceTransformer(\"paraphrase-MiniLM-L6-v2\")\n",
    "\n",
    "# Ground truth and predictions\n",
    "y_true = []\n",
    "y_pred_t5 = []\n",
    "y_pred_rule = []\n",
    "y_pred_gpt2 = []\n",
    "y_pred_bart = []\n",
    "\n",
    "THRESHOLD = 0.9\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    words = eval(row['input_words']) if isinstance(row['input_words'], str) else row['input_words']\n",
    "    target = row['target_sentence'].strip()\n",
    "    target_emb = embedder.encode(target, convert_to_tensor=True)\n",
    "\n",
    "    def is_match(gen):\n",
    "        gen_emb = embedder.encode(gen.strip(), convert_to_tensor=True)\n",
    "        sim = util.cos_sim(target_emb, gen_emb).item()\n",
    "        return 1 if sim >= THRESHOLD else 0\n",
    "\n",
    "    y_true.append(1)\n",
    "\n",
    "    y_pred_t5.append(is_match(t5_generate(words)))\n",
    "    y_pred_rule.append(is_match(rule_based_generate(words)))\n",
    "    y_pred_gpt2.append(is_match(gpt2_generate(words)))\n",
    "    y_pred_bart.append(is_match(bart_generate(words)))\n",
    "\n",
    "# Metric Summary Table\n",
    "def get_metrics(preds):\n",
    "    return {\n",
    "        \"Precision\": precision_score(y_true, preds),\n",
    "        \"Recall\": recall_score(y_true, preds),\n",
    "        \"F1 Score\": f1_score(y_true, preds),\n",
    "    }\n",
    "\n",
    "results = {\n",
    "    \"T5\": get_metrics(y_pred_t5),\n",
    "    \"Rule-based\": get_metrics(y_pred_rule),\n",
    "    \"GPT-2\": get_metrics(y_pred_gpt2),\n",
    "    \"BART\": get_metrics(y_pred_bart),\n",
    "}\n",
    "\n",
    "df_metrics = pd.DataFrame(results).T.reset_index().rename(columns={\"index\": \"Model\"})\n",
    "print(df_metrics)\n",
    "\n",
    "\n",
    "# Confusion Matrix Plotting\n",
    "def show_confusion(preds, name):\n",
    "    cm = confusion_matrix(y_true, preds)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Wrong\", \"Correct\"])\n",
    "    disp.plot(cmap=\"Blues\")\n",
    "    plt.title(f\"{name} Confusion Matrix (Threshold ≥ {THRESHOLD})\")\n",
    "    plt.show()\n",
    "\n",
    "show_confusion(y_pred_t5, \"T5\")\n",
    "show_confusion(y_pred_rule, \"Rule-based\")\n",
    "show_confusion(y_pred_gpt2, \"GPT-2\")\n",
    "show_confusion(y_pred_bart, \"BART\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3933ac2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv310 (3.10.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
