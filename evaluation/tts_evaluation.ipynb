{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb68f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import tempfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "from tqdm import tqdm\n",
    "from gtts import gTTS\n",
    "from TTS.api import TTS\n",
    "import whisper\n",
    "from jiwer import wer, cer, Compose, ToLowerCase, RemovePunctuation, RemoveMultipleSpaces, Strip\n",
    "import torch\n",
    "from transformers import VitsModel, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d614939c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TTS + ASR models...\n",
      " > tts_models/en/ljspeech/tacotron2-DDC is already downloaded.\n",
      " > vocoder_models/en/ljspeech/hifigan_v2 is already downloaded.\n",
      " > Using model: Tacotron2\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:False\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:2.718281828459045\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Model's reduction rate `r` is set to: 1\n",
      " > Vocoder Model: hifigan\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:False\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:2.718281828459045\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Generator Model: hifigan_generator\n",
      " > Discriminator Model: hifigan_discriminator\n",
      "Removing weight norm...\n",
      "All models loaded successfully!\n",
      "Loading extra TTS models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/mms-tts-eng were not used when initializing VitsModel: ['flow.flows.3.wavenet.res_skip_layers.2.weight_g', 'flow.flows.0.wavenet.in_layers.1.weight_v', 'posterior_encoder.wavenet.res_skip_layers.2.weight_g', 'posterior_encoder.wavenet.res_skip_layers.15.weight_v', 'posterior_encoder.wavenet.in_layers.5.weight_g', 'posterior_encoder.wavenet.res_skip_layers.5.weight_g', 'flow.flows.2.wavenet.res_skip_layers.2.weight_v', 'flow.flows.2.wavenet.res_skip_layers.0.weight_v', 'posterior_encoder.wavenet.res_skip_layers.4.weight_g', 'flow.flows.1.wavenet.in_layers.0.weight_v', 'flow.flows.0.wavenet.res_skip_layers.2.weight_g', 'posterior_encoder.wavenet.in_layers.14.weight_v', 'posterior_encoder.wavenet.in_layers.13.weight_v', 'posterior_encoder.wavenet.in_layers.2.weight_g', 'posterior_encoder.wavenet.in_layers.4.weight_v', 'posterior_encoder.wavenet.in_layers.9.weight_g', 'flow.flows.2.wavenet.in_layers.3.weight_v', 'flow.flows.3.wavenet.in_layers.2.weight_g', 'posterior_encoder.wavenet.in_layers.15.weight_g', 'posterior_encoder.wavenet.res_skip_layers.11.weight_v', 'flow.flows.0.wavenet.res_skip_layers.1.weight_v', 'flow.flows.3.wavenet.res_skip_layers.0.weight_g', 'flow.flows.1.wavenet.in_layers.3.weight_v', 'flow.flows.3.wavenet.in_layers.1.weight_v', 'flow.flows.0.wavenet.in_layers.1.weight_g', 'posterior_encoder.wavenet.res_skip_layers.14.weight_g', 'posterior_encoder.wavenet.in_layers.12.weight_g', 'flow.flows.2.wavenet.res_skip_layers.2.weight_g', 'posterior_encoder.wavenet.res_skip_layers.0.weight_v', 'flow.flows.1.wavenet.res_skip_layers.1.weight_v', 'flow.flows.1.wavenet.res_skip_layers.2.weight_v', 'posterior_encoder.wavenet.res_skip_layers.1.weight_g', 'posterior_encoder.wavenet.in_layers.9.weight_v', 'flow.flows.1.wavenet.res_skip_layers.0.weight_v', 'posterior_encoder.wavenet.in_layers.0.weight_v', 'flow.flows.2.wavenet.res_skip_layers.3.weight_v', 'flow.flows.0.wavenet.res_skip_layers.1.weight_g', 'flow.flows.1.wavenet.res_skip_layers.2.weight_g', 'posterior_encoder.wavenet.in_layers.7.weight_g', 'flow.flows.2.wavenet.in_layers.1.weight_g', 'posterior_encoder.wavenet.res_skip_layers.2.weight_v', 'flow.flows.1.wavenet.in_layers.3.weight_g', 'flow.flows.3.wavenet.in_layers.0.weight_v', 'flow.flows.1.wavenet.res_skip_layers.0.weight_g', 'posterior_encoder.wavenet.in_layers.12.weight_v', 'flow.flows.3.wavenet.res_skip_layers.1.weight_g', 'flow.flows.3.wavenet.in_layers.0.weight_g', 'flow.flows.0.wavenet.res_skip_layers.3.weight_v', 'flow.flows.1.wavenet.res_skip_layers.3.weight_v', 'flow.flows.3.wavenet.in_layers.2.weight_v', 'posterior_encoder.wavenet.res_skip_layers.12.weight_g', 'flow.flows.0.wavenet.in_layers.0.weight_g', 'flow.flows.0.wavenet.in_layers.3.weight_g', 'posterior_encoder.wavenet.in_layers.15.weight_v', 'posterior_encoder.wavenet.res_skip_layers.10.weight_v', 'flow.flows.1.wavenet.res_skip_layers.3.weight_g', 'flow.flows.2.wavenet.in_layers.3.weight_g', 'posterior_encoder.wavenet.res_skip_layers.13.weight_g', 'flow.flows.3.wavenet.res_skip_layers.3.weight_g', 'flow.flows.2.wavenet.res_skip_layers.1.weight_g', 'flow.flows.0.wavenet.in_layers.2.weight_g', 'posterior_encoder.wavenet.res_skip_layers.15.weight_g', 'posterior_encoder.wavenet.in_layers.5.weight_v', 'posterior_encoder.wavenet.res_skip_layers.8.weight_g', 'posterior_encoder.wavenet.in_layers.7.weight_v', 'posterior_encoder.wavenet.res_skip_layers.7.weight_g', 'posterior_encoder.wavenet.res_skip_layers.9.weight_v', 'posterior_encoder.wavenet.res_skip_layers.10.weight_g', 'posterior_encoder.wavenet.in_layers.10.weight_v', 'posterior_encoder.wavenet.res_skip_layers.4.weight_v', 'flow.flows.1.wavenet.in_layers.0.weight_g', 'posterior_encoder.wavenet.res_skip_layers.8.weight_v', 'posterior_encoder.wavenet.res_skip_layers.12.weight_v', 'posterior_encoder.wavenet.in_layers.4.weight_g', 'posterior_encoder.wavenet.res_skip_layers.9.weight_g', 'posterior_encoder.wavenet.res_skip_layers.5.weight_v', 'posterior_encoder.wavenet.res_skip_layers.13.weight_v', 'posterior_encoder.wavenet.in_layers.3.weight_g', 'posterior_encoder.wavenet.res_skip_layers.11.weight_g', 'flow.flows.2.wavenet.res_skip_layers.1.weight_v', 'posterior_encoder.wavenet.in_layers.11.weight_v', 'posterior_encoder.wavenet.in_layers.3.weight_v', 'flow.flows.0.wavenet.in_layers.0.weight_v', 'posterior_encoder.wavenet.in_layers.6.weight_v', 'flow.flows.3.wavenet.in_layers.3.weight_g', 'flow.flows.2.wavenet.in_layers.1.weight_v', 'posterior_encoder.wavenet.res_skip_layers.7.weight_v', 'posterior_encoder.wavenet.in_layers.13.weight_g', 'posterior_encoder.wavenet.in_layers.1.weight_v', 'posterior_encoder.wavenet.in_layers.0.weight_g', 'flow.flows.2.wavenet.in_layers.2.weight_v', 'posterior_encoder.wavenet.res_skip_layers.3.weight_v', 'posterior_encoder.wavenet.in_layers.11.weight_g', 'posterior_encoder.wavenet.in_layers.8.weight_v', 'flow.flows.3.wavenet.res_skip_layers.0.weight_v', 'posterior_encoder.wavenet.res_skip_layers.14.weight_v', 'posterior_encoder.wavenet.res_skip_layers.6.weight_g', 'flow.flows.0.wavenet.in_layers.2.weight_v', 'flow.flows.2.wavenet.res_skip_layers.0.weight_g', 'posterior_encoder.wavenet.res_skip_layers.3.weight_g', 'flow.flows.0.wavenet.res_skip_layers.0.weight_v', 'flow.flows.3.wavenet.in_layers.1.weight_g', 'flow.flows.0.wavenet.res_skip_layers.3.weight_g', 'flow.flows.0.wavenet.res_skip_layers.0.weight_g', 'flow.flows.1.wavenet.in_layers.2.weight_v', 'flow.flows.0.wavenet.in_layers.3.weight_v', 'posterior_encoder.wavenet.in_layers.2.weight_v', 'posterior_encoder.wavenet.in_layers.8.weight_g', 'posterior_encoder.wavenet.in_layers.6.weight_g', 'flow.flows.3.wavenet.res_skip_layers.3.weight_v', 'flow.flows.0.wavenet.res_skip_layers.2.weight_v', 'posterior_encoder.wavenet.in_layers.10.weight_g', 'flow.flows.3.wavenet.res_skip_layers.1.weight_v', 'flow.flows.1.wavenet.res_skip_layers.1.weight_g', 'flow.flows.2.wavenet.in_layers.0.weight_g', 'posterior_encoder.wavenet.res_skip_layers.0.weight_g', 'flow.flows.2.wavenet.in_layers.2.weight_g', 'flow.flows.2.wavenet.res_skip_layers.3.weight_g', 'flow.flows.2.wavenet.in_layers.0.weight_v', 'flow.flows.1.wavenet.in_layers.1.weight_g', 'posterior_encoder.wavenet.res_skip_layers.6.weight_v', 'posterior_encoder.wavenet.res_skip_layers.1.weight_v', 'posterior_encoder.wavenet.in_layers.1.weight_g', 'flow.flows.3.wavenet.res_skip_layers.2.weight_v', 'flow.flows.3.wavenet.in_layers.3.weight_v', 'posterior_encoder.wavenet.in_layers.14.weight_g', 'flow.flows.1.wavenet.in_layers.1.weight_v', 'flow.flows.1.wavenet.in_layers.2.weight_g']\n",
      "- This IS expected if you are initializing VitsModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VitsModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of VitsModel were not initialized from the model checkpoint at facebook/mms-tts-eng and are newly initialized: ['posterior_encoder.wavenet.in_layers.2.parametrizations.weight.original1', 'flow.flows.3.wavenet.in_layers.0.parametrizations.weight.original0', 'flow.flows.0.wavenet.res_skip_layers.2.parametrizations.weight.original1', 'flow.flows.2.wavenet.res_skip_layers.2.parametrizations.weight.original1', 'flow.flows.3.wavenet.in_layers.1.parametrizations.weight.original0', 'flow.flows.1.wavenet.in_layers.1.parametrizations.weight.original1', 'flow.flows.2.wavenet.in_layers.0.parametrizations.weight.original1', 'flow.flows.3.wavenet.res_skip_layers.3.parametrizations.weight.original1', 'flow.flows.3.wavenet.in_layers.1.parametrizations.weight.original1', 'posterior_encoder.wavenet.in_layers.12.parametrizations.weight.original0', 'posterior_encoder.wavenet.in_layers.10.parametrizations.weight.original1', 'flow.flows.3.wavenet.in_layers.3.parametrizations.weight.original0', 'posterior_encoder.wavenet.res_skip_layers.14.parametrizations.weight.original1', 'flow.flows.1.wavenet.res_skip_layers.3.parametrizations.weight.original1', 'posterior_encoder.wavenet.in_layers.7.parametrizations.weight.original0', 'posterior_encoder.wavenet.res_skip_layers.6.parametrizations.weight.original0', 'posterior_encoder.wavenet.res_skip_layers.5.parametrizations.weight.original1', 'posterior_encoder.wavenet.in_layers.13.parametrizations.weight.original0', 'flow.flows.0.wavenet.in_layers.1.parametrizations.weight.original0', 'posterior_encoder.wavenet.in_layers.8.parametrizations.weight.original0', 'flow.flows.0.wavenet.res_skip_layers.1.parametrizations.weight.original0', 'posterior_encoder.wavenet.in_layers.0.parametrizations.weight.original1', 'flow.flows.3.wavenet.in_layers.2.parametrizations.weight.original0', 'flow.flows.1.wavenet.in_layers.3.parametrizations.weight.original0', 'posterior_encoder.wavenet.res_skip_layers.12.parametrizations.weight.original0', 'posterior_encoder.wavenet.in_layers.1.parametrizations.weight.original1', 'flow.flows.3.wavenet.res_skip_layers.2.parametrizations.weight.original0', 'posterior_encoder.wavenet.res_skip_layers.6.parametrizations.weight.original1', 'flow.flows.2.wavenet.in_layers.3.parametrizations.weight.original0', 'posterior_encoder.wavenet.res_skip_layers.0.parametrizations.weight.original0', 'posterior_encoder.wavenet.res_skip_layers.7.parametrizations.weight.original1', 'posterior_encoder.wavenet.res_skip_layers.15.parametrizations.weight.original1', 'posterior_encoder.wavenet.res_skip_layers.8.parametrizations.weight.original1', 'flow.flows.0.wavenet.res_skip_layers.3.parametrizations.weight.original0', 'posterior_encoder.wavenet.in_layers.3.parametrizations.weight.original0', 'flow.flows.2.wavenet.in_layers.3.parametrizations.weight.original1', 'posterior_encoder.wavenet.res_skip_layers.2.parametrizations.weight.original0', 'posterior_encoder.wavenet.in_layers.10.parametrizations.weight.original0', 'posterior_encoder.wavenet.in_layers.7.parametrizations.weight.original1', 'flow.flows.0.wavenet.res_skip_layers.2.parametrizations.weight.original0', 'posterior_encoder.wavenet.res_skip_layers.15.parametrizations.weight.original0', 'flow.flows.3.wavenet.res_skip_layers.1.parametrizations.weight.original0', 'posterior_encoder.wavenet.res_skip_layers.1.parametrizations.weight.original0', 'flow.flows.1.wavenet.res_skip_layers.3.parametrizations.weight.original0', 'flow.flows.3.wavenet.res_skip_layers.3.parametrizations.weight.original0', 'posterior_encoder.wavenet.in_layers.2.parametrizations.weight.original0', 'posterior_encoder.wavenet.res_skip_layers.13.parametrizations.weight.original0', 'posterior_encoder.wavenet.in_layers.11.parametrizations.weight.original1', 'flow.flows.2.wavenet.in_layers.1.parametrizations.weight.original0', 'posterior_encoder.wavenet.in_layers.14.parametrizations.weight.original0', 'posterior_encoder.wavenet.res_skip_layers.8.parametrizations.weight.original0', 'posterior_encoder.wavenet.in_layers.5.parametrizations.weight.original0', 'flow.flows.2.wavenet.in_layers.2.parametrizations.weight.original0', 'flow.flows.2.wavenet.res_skip_layers.3.parametrizations.weight.original0', 'flow.flows.3.wavenet.res_skip_layers.0.parametrizations.weight.original0', 'flow.flows.1.wavenet.in_layers.3.parametrizations.weight.original1', 'flow.flows.1.wavenet.res_skip_layers.2.parametrizations.weight.original1', 'flow.flows.1.wavenet.in_layers.0.parametrizations.weight.original0', 'posterior_encoder.wavenet.in_layers.5.parametrizations.weight.original1', 'posterior_encoder.wavenet.res_skip_layers.9.parametrizations.weight.original1', 'posterior_encoder.wavenet.in_layers.8.parametrizations.weight.original1', 'posterior_encoder.wavenet.in_layers.15.parametrizations.weight.original1', 'flow.flows.0.wavenet.res_skip_layers.0.parametrizations.weight.original1', 'posterior_encoder.wavenet.in_layers.13.parametrizations.weight.original1', 'posterior_encoder.wavenet.in_layers.4.parametrizations.weight.original0', 'posterior_encoder.wavenet.res_skip_layers.11.parametrizations.weight.original0', 'posterior_encoder.wavenet.res_skip_layers.13.parametrizations.weight.original1', 'posterior_encoder.wavenet.res_skip_layers.5.parametrizations.weight.original0', 'flow.flows.3.wavenet.in_layers.2.parametrizations.weight.original1', 'posterior_encoder.wavenet.in_layers.12.parametrizations.weight.original1', 'posterior_encoder.wavenet.in_layers.9.parametrizations.weight.original0', 'flow.flows.0.wavenet.in_layers.0.parametrizations.weight.original0', 'flow.flows.2.wavenet.in_layers.0.parametrizations.weight.original0', 'flow.flows.0.wavenet.in_layers.3.parametrizations.weight.original1', 'flow.flows.2.wavenet.res_skip_layers.1.parametrizations.weight.original0', 'flow.flows.0.wavenet.in_layers.0.parametrizations.weight.original1', 'posterior_encoder.wavenet.res_skip_layers.3.parametrizations.weight.original1', 'flow.flows.1.wavenet.res_skip_layers.0.parametrizations.weight.original1', 'posterior_encoder.wavenet.in_layers.4.parametrizations.weight.original1', 'flow.flows.0.wavenet.in_layers.1.parametrizations.weight.original1', 'flow.flows.2.wavenet.in_layers.2.parametrizations.weight.original1', 'flow.flows.1.wavenet.res_skip_layers.1.parametrizations.weight.original1', 'posterior_encoder.wavenet.in_layers.14.parametrizations.weight.original1', 'posterior_encoder.wavenet.res_skip_layers.12.parametrizations.weight.original1', 'flow.flows.0.wavenet.in_layers.2.parametrizations.weight.original0', 'posterior_encoder.wavenet.res_skip_layers.2.parametrizations.weight.original1', 'posterior_encoder.wavenet.res_skip_layers.10.parametrizations.weight.original1', 'posterior_encoder.wavenet.res_skip_layers.10.parametrizations.weight.original0', 'flow.flows.2.wavenet.res_skip_layers.3.parametrizations.weight.original1', 'flow.flows.1.wavenet.in_layers.0.parametrizations.weight.original1', 'flow.flows.2.wavenet.res_skip_layers.2.parametrizations.weight.original0', 'flow.flows.1.wavenet.res_skip_layers.1.parametrizations.weight.original0', 'flow.flows.2.wavenet.res_skip_layers.0.parametrizations.weight.original0', 'posterior_encoder.wavenet.in_layers.0.parametrizations.weight.original0', 'flow.flows.2.wavenet.res_skip_layers.0.parametrizations.weight.original1', 'posterior_encoder.wavenet.res_skip_layers.9.parametrizations.weight.original0', 'posterior_encoder.wavenet.res_skip_layers.3.parametrizations.weight.original0', 'flow.flows.2.wavenet.in_layers.1.parametrizations.weight.original1', 'posterior_encoder.wavenet.in_layers.11.parametrizations.weight.original0', 'posterior_encoder.wavenet.res_skip_layers.0.parametrizations.weight.original1', 'posterior_encoder.wavenet.res_skip_layers.7.parametrizations.weight.original0', 'flow.flows.1.wavenet.res_skip_layers.0.parametrizations.weight.original0', 'flow.flows.0.wavenet.in_layers.2.parametrizations.weight.original1', 'posterior_encoder.wavenet.res_skip_layers.11.parametrizations.weight.original1', 'posterior_encoder.wavenet.res_skip_layers.4.parametrizations.weight.original1', 'flow.flows.0.wavenet.res_skip_layers.1.parametrizations.weight.original1', 'flow.flows.1.wavenet.res_skip_layers.2.parametrizations.weight.original0', 'posterior_encoder.wavenet.res_skip_layers.14.parametrizations.weight.original0', 'posterior_encoder.wavenet.in_layers.3.parametrizations.weight.original1', 'flow.flows.2.wavenet.res_skip_layers.1.parametrizations.weight.original1', 'posterior_encoder.wavenet.in_layers.6.parametrizations.weight.original1', 'flow.flows.3.wavenet.in_layers.3.parametrizations.weight.original1', 'posterior_encoder.wavenet.in_layers.15.parametrizations.weight.original0', 'posterior_encoder.wavenet.in_layers.1.parametrizations.weight.original0', 'posterior_encoder.wavenet.in_layers.6.parametrizations.weight.original0', 'flow.flows.3.wavenet.res_skip_layers.2.parametrizations.weight.original1', 'flow.flows.3.wavenet.res_skip_layers.0.parametrizations.weight.original1', 'posterior_encoder.wavenet.in_layers.9.parametrizations.weight.original1', 'flow.flows.1.wavenet.in_layers.2.parametrizations.weight.original0', 'flow.flows.3.wavenet.in_layers.0.parametrizations.weight.original1', 'flow.flows.1.wavenet.in_layers.1.parametrizations.weight.original0', 'posterior_encoder.wavenet.res_skip_layers.1.parametrizations.weight.original1', 'flow.flows.0.wavenet.res_skip_layers.0.parametrizations.weight.original0', 'flow.flows.1.wavenet.in_layers.2.parametrizations.weight.original1', 'flow.flows.3.wavenet.res_skip_layers.1.parametrizations.weight.original1', 'flow.flows.0.wavenet.in_layers.3.parametrizations.weight.original0', 'posterior_encoder.wavenet.res_skip_layers.4.parametrizations.weight.original0', 'flow.flows.0.wavenet.res_skip_layers.3.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra models loaded!\n"
     ]
    }
   ],
   "source": [
    "# Initialize TTS and ASR models\n",
    "print(\"Loading TTS + ASR models...\")\n",
    "tts_coqui = TTS(model_name=\"tts_models/en/ljspeech/tacotron2-DDC\", progress_bar=False, gpu=False)  # Coqui TTS\n",
    "asr = whisper.load_model(\"base\")  # Whisper ASR\n",
    "print(\"All models loaded successfully!\")\n",
    "\n",
    "print(\"Loading extra TTS models...\")\n",
    "mms_model_id = \"facebook/mms-tts-eng\"\n",
    "mms_model = VitsModel.from_pretrained(mms_model_id)           # Meta MMS TTS model (VITS)\n",
    "mms_tok   = AutoTokenizer.from_pretrained(mms_model_id)       # Corresponding tokenizer\n",
    "mms_sr    = mms_model.config.sampling_rate                    # Sample rate config\n",
    "print(\"Extra models loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbf413b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Better person.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Let's go outside to play.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>An uncle is reading a story.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A cat hiding in a closet.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cows on a farm.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       sentence\n",
       "0                Better person.\n",
       "1     Let's go outside to play.\n",
       "2  An uncle is reading a story.\n",
       "3     A cat hiding in a closet.\n",
       "4               Cows on a farm."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"Text_To_Speech_Dataset.csv\")\n",
    "\n",
    "# Use all sentences instead of a random sample\n",
    "samples = df.reset_index(drop=True)\n",
    "\n",
    "samples.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9c84d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function: ASR transcription with librosa\n",
    "def transcribe_with_librosa(asr, file_path):\n",
    "    \"\"\"\n",
    "    Load audio with librosa and transcribe it using Whisper ASR.\n",
    "    Handles issues with file path encoding on Windows.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        audio_data, sr = librosa.load(file_path, sr=16000, mono=True)\n",
    "        result = asr.transcribe(audio_data, fp16=False, language='en')\n",
    "        return result[\"text\"].strip()\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Librosa transcription failed: {str(e)}\")\n",
    "\n",
    "\n",
    "# Core evaluation function for a given TTS model\n",
    "def evaluate_tts_model(tts_func, model_name, samples):\n",
    "    \"\"\"\n",
    "    Run TTS on each sample, transcribe the result, and compute evaluation metrics.\n",
    "    Returns a dictionary with WER, CER, accuracy, and more.\n",
    "    \"\"\"\n",
    "    print(f\"\\nEvaluating {model_name}...\")\n",
    "    ground_truths, transcriptions = [], []\n",
    "\n",
    "    for idx, row in tqdm(samples.iterrows(), total=len(samples), desc=model_name):\n",
    "        sentence = row['sentence']\n",
    "        audio_path = os.path.join(os.getcwd(), f\"tts_eval_{model_name}_{idx}.wav\")\n",
    "\n",
    "        try:\n",
    "            success = tts_func(sentence, audio_path)\n",
    "            if not success:\n",
    "                continue\n",
    "\n",
    "            time.sleep(0.3)  # Ensure audio file is fully written\n",
    "\n",
    "            # If file is valid, transcribe\n",
    "            if os.path.exists(audio_path) and os.path.getsize(audio_path) > 1000:\n",
    "                transcription = transcribe_with_librosa(asr, audio_path)\n",
    "                ground_truths.append(sentence.lower())\n",
    "                transcriptions.append(transcription.lower())\n",
    "            else:\n",
    "                print(f\"Audio file issue for: {sentence}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed for '{sentence[:30]}...': {str(e)}\")\n",
    "        finally:\n",
    "            # Clean up generated audio file\n",
    "            if os.path.exists(audio_path):\n",
    "                try:\n",
    "                    os.remove(audio_path)\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "    # Compute metrics if we have valid data\n",
    "    results = {}\n",
    "    if ground_truths and transcriptions:\n",
    "        exact_matches = sum(1 for gt, pred in zip(ground_truths, transcriptions) if gt == pred)\n",
    "\n",
    "        normalize = Compose([ToLowerCase(), RemovePunctuation(), RemoveMultipleSpaces(), Strip()])\n",
    "        norm_gt   = [normalize(gt) for gt in ground_truths]\n",
    "        norm_pred = [normalize(pred) for pred in transcriptions]\n",
    "\n",
    "        wer_score = wer(norm_gt, norm_pred)\n",
    "        cer_score = cer(norm_gt, norm_pred)\n",
    "\n",
    "        results = {\n",
    "            'model': model_name,\n",
    "            'samples_processed': len(ground_truths),\n",
    "            'exact_matches': exact_matches,\n",
    "            'exact_match_rate': exact_matches / len(ground_truths) * 100,\n",
    "            'wer': wer_score,\n",
    "            'cer': cer_score,\n",
    "            'word_accuracy': (1 - wer_score) * 100,\n",
    "            'char_accuracy': (1 - cer_score) * 100,\n",
    "            'ground_truths': ground_truths,\n",
    "            'transcriptions': transcriptions\n",
    "        }\n",
    "\n",
    "        # Print summary\n",
    "        print(f\"{model_name} Results:\")\n",
    "        print(f\"   Samples processed: {len(ground_truths)}/{len(samples)}\")\n",
    "        print(f\"   Exact matches: {exact_matches}/{len(ground_truths)} ({results['exact_match_rate']:.1f}%)\")\n",
    "        print(f\"   WER: {wer_score:.4f} ({wer_score*100:.2f}%)\")\n",
    "        print(f\"   CER: {cer_score:.4f} ({cer_score*100:.2f}%)\")\n",
    "        print(f\"   Word Accuracy: {results['word_accuracy']:.2f}%\")\n",
    "        print(f\"   Character Accuracy: {results['char_accuracy']:.2f}%\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3addeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TTS wrapper functions for each model\n",
    "def coqui_tts_func(text, output_path):\n",
    "    \"\"\"Generate TTS output using Coqui and save to file.\"\"\"\n",
    "    try:\n",
    "        tts_coqui.tts_to_file(text=text, file_path=output_path)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def gtts_tts_func(text, output_path):\n",
    "    \"\"\"Generate TTS using Google TTS and save to file.\"\"\"\n",
    "    try:\n",
    "        out_dir = os.path.dirname(output_path)\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "        gTTS(text=text, lang=\"en\").save(output_path)\n",
    "        return os.path.exists(output_path) and os.path.getsize(output_path) > 1000\n",
    "    except Exception as e:\n",
    "        print(f\"gTTS error: {e}\")\n",
    "        return False\n",
    "\n",
    "def mms_tts_func(text, output_path):\n",
    "    \"\"\"Generate TTS using Meta MMS-TTS (VITS) and save to file.\"\"\"\n",
    "    try:\n",
    "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "        inputs = mms_tok(text, return_tensors=\"pt\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            wave = mms_model(**inputs).waveform.squeeze().cpu().numpy()\n",
    "\n",
    "        # Normalize waveform volume\n",
    "        if np.max(np.abs(wave)) > 0:\n",
    "            wave = wave / np.max(np.abs(wave)) * 0.95\n",
    "        wave = wave.astype(\"float32\")\n",
    "\n",
    "        sf.write(output_path, wave, samplerate=mms_sr, format=\"WAV\", subtype=\"PCM_16\")\n",
    "        return os.path.exists(output_path) and os.path.getsize(output_path) > 1000\n",
    "    except Exception as e:\n",
    "        print(f\"MMS-TTS error: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3eb563f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Coqui TTS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Coqui TTS:   0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Text splitted to sentences.\n",
      "['Better person.']\n",
      " > Processing time: 2.996001720428467\n",
      " > Real-time factor: 0.385694990281689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Coqui TTS:   7%|▋         | 1/15 [00:04<00:57,  4.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Text splitted to sentences.\n",
      "[\"Let's go outside to play.\"]\n",
      " > Processing time: 0.9240012168884277\n",
      " > Real-time factor: 0.31826772732426006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Coqui TTS:  13%|█▎        | 2/15 [00:05<00:35,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Text splitted to sentences.\n",
      "['An uncle is reading a story.']\n",
      " > Processing time: 0.8029990196228027\n",
      " > Real-time factor: 0.2917566633054772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Coqui TTS:  20%|██        | 3/15 [00:07<00:26,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Text splitted to sentences.\n",
      "['A cat hiding in a closet.']\n",
      " > Processing time: 0.7709982395172119\n",
      " > Real-time factor: 0.29905205427375675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Coqui TTS:  27%|██▋       | 4/15 [00:09<00:21,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Text splitted to sentences.\n",
      "['Cows on a farm.']\n",
      " > Processing time: 0.4719984531402588\n",
      " > Real-time factor: 0.2691240662945466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Coqui TTS:  33%|███▎      | 5/15 [00:10<00:16,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Text splitted to sentences.\n",
      "['A man tries to dry many clothes in a dryer.']\n",
      " > Processing time: 1.011997938156128\n",
      " > Real-time factor: 0.302594848887267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Coqui TTS:  40%|████      | 6/15 [00:12<00:15,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Text splitted to sentences.\n",
      "['The baby is crying and hungry.']\n",
      " > Processing time: 0.7269992828369141\n",
      " > Real-time factor: 0.28715846565194103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Coqui TTS:  47%|████▋     | 7/15 [00:13<00:13,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Text splitted to sentences.\n",
      "['The shower is dirty.']\n",
      " > Processing time: 0.466001033782959\n",
      " > Real-time factor: 0.2571916999127514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Coqui TTS:  53%|█████▎    | 8/15 [00:14<00:10,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Text splitted to sentences.\n",
      "['A girl is dancing to music.']\n",
      " > Processing time: 0.7079997062683105\n",
      " > Real-time factor: 0.2783772026251114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Coqui TTS:  60%|██████    | 9/15 [00:16<00:09,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Text splitted to sentences.\n",
      "['A girl hugging a puppy.']\n",
      " > Processing time: 0.6380026340484619\n",
      " > Real-time factor: 0.29066029092497075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Coqui TTS:  67%|██████▋   | 10/15 [00:17<00:07,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Text splitted to sentences.\n",
      "['Fish swimming in a tank.']\n",
      " > Processing time: 0.68499755859375\n",
      " > Real-time factor: 0.30092835844342103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Coqui TTS:  73%|███████▎  | 11/15 [00:19<00:06,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Text splitted to sentences.\n",
      "['A baby crying in a bed.']\n",
      " > Processing time: 0.764000415802002\n",
      " > Real-time factor: 0.3031638563279971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Coqui TTS:  80%|████████  | 12/15 [00:21<00:04,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Text splitted to sentences.\n",
      "['A boy is running on the grass.']\n",
      " > Processing time: 0.7930004596710205\n",
      " > Real-time factor: 0.29181675793968626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Coqui TTS:  87%|████████▋ | 13/15 [00:22<00:03,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Text splitted to sentences.\n",
      "['A teacher talking to a class.']\n",
      " > Processing time: 0.8086016178131104\n",
      " > Real-time factor: 0.29503682937481934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Coqui TTS:  93%|█████████▎| 14/15 [00:24<00:01,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Text splitted to sentences.\n",
      "['Mom says no.']\n",
      " > Processing time: 0.46700000762939453\n",
      " > Real-time factor: 0.2577430458607366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Coqui TTS: 100%|██████████| 15/15 [00:25<00:00,  1.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coqui TTS Results:\n",
      "   Samples processed: 15/15\n",
      "   Exact matches: 10/15 (66.7%)\n",
      "   WER: 0.1975 (19.75%)\n",
      "   CER: 0.2074 (20.74%)\n",
      "   Word Accuracy: 80.25%\n",
      "   Character Accuracy: 79.26%\n",
      "\n",
      "Evaluating Google TTS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Google TTS: 100%|██████████| 15/15 [00:19<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google TTS Results:\n",
      "   Samples processed: 15/15\n",
      "   Exact matches: 13/15 (86.7%)\n",
      "   WER: 0.0123 (1.23%)\n",
      "   CER: 0.0085 (0.85%)\n",
      "   Word Accuracy: 98.77%\n",
      "   Character Accuracy: 99.15%\n",
      "\n",
      "Evaluating Meta MMS-TTS (facebook/mms-tts-eng)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Meta MMS-TTS (facebook/mms-tts-eng): 100%|██████████| 15/15 [00:18<00:00,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta MMS-TTS (facebook/mms-tts-eng) Results:\n",
      "   Samples processed: 15/15\n",
      "   Exact matches: 6/15 (40.0%)\n",
      "   WER: 0.2593 (25.93%)\n",
      "   CER: 0.1562 (15.62%)\n",
      "   Word Accuracy: 74.07%\n",
      "   Character Accuracy: 84.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run evaluation for all 3 models\n",
    "results = {}\n",
    "results[\"Coqui\"]    = evaluate_tts_model(coqui_tts_func, \"Coqui TTS\", samples)\n",
    "results[\"gTTS\"]     = evaluate_tts_model(gtts_tts_func, \"Google TTS\", samples)\n",
    "results[\"MMS_TTS\"]  = evaluate_tts_model(mms_tts_func, \"Meta MMS-TTS (facebook/mms-tts-eng)\", samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3907165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Samples</th>\n",
       "      <th>Exact Match %</th>\n",
       "      <th>WER %</th>\n",
       "      <th>CER %</th>\n",
       "      <th>Word Acc %</th>\n",
       "      <th>Char Acc %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Coqui TTS</td>\n",
       "      <td>15</td>\n",
       "      <td>66.7</td>\n",
       "      <td>19.75</td>\n",
       "      <td>20.74</td>\n",
       "      <td>80.25</td>\n",
       "      <td>79.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Google TTS</td>\n",
       "      <td>15</td>\n",
       "      <td>86.7</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.85</td>\n",
       "      <td>98.77</td>\n",
       "      <td>99.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Meta MMS-TTS (facebook/mms-tts-eng)</td>\n",
       "      <td>15</td>\n",
       "      <td>40.0</td>\n",
       "      <td>25.93</td>\n",
       "      <td>15.62</td>\n",
       "      <td>74.07</td>\n",
       "      <td>84.38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Model  Samples Exact Match %  WER %  CER %  \\\n",
       "0                            Coqui TTS       15          66.7  19.75  20.74   \n",
       "1                           Google TTS       15          86.7   1.23   0.85   \n",
       "2  Meta MMS-TTS (facebook/mms-tts-eng)       15          40.0  25.93  15.62   \n",
       "\n",
       "  Word Acc % Char Acc %  \n",
       "0      80.25      79.26  \n",
       "1      98.77      99.15  \n",
       "2      74.07      84.38  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summarize results in tabular format\n",
    "summary_rows = []\n",
    "for k, v in results.items():\n",
    "    if v:\n",
    "        summary_rows.append({\n",
    "            \"Model\": v['model'],\n",
    "            \"Samples\": v['samples_processed'],\n",
    "            \"Exact Match %\": f\"{v['exact_match_rate']:.1f}\",\n",
    "            \"WER %\": f\"{v['wer']*100:.2f}\",\n",
    "            \"CER %\": f\"{v['cer']*100:.2f}\",\n",
    "            \"Word Acc %\": f\"{v['word_accuracy']:.2f}\",\n",
    "            \"Char Acc %\": f\"{v['char_accuracy']:.2f}\",\n",
    "        })\n",
    "\n",
    "df_summary = pd.DataFrame(summary_rows)\n",
    "df_summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv310 (3.10.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
